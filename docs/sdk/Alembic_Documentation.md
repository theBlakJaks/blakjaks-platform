# Alembic Documentation — Complete Reference

> **Source:** [alembic.sqlalchemy.org](https://alembic.sqlalchemy.org) — Alembic latest  
> **Repository:** [github.com/sqlalchemy/alembic](https://github.com/sqlalchemy/alembic)  
> **Requirements:** SQLAlchemy ≥ 1.4.0 · Python ≥ 3.9

Alembic is a lightweight database migration tool for usage with the SQLAlchemy Database Toolkit for Python.

---

## Table of Contents

1. [Installation & Front Matter](#1-installation--front-matter)
2. [Tutorial](#2-tutorial)
3. [Auto Generating Migrations](#3-auto-generating-migrations)
4. [Generating SQL Scripts (Offline Mode)](#4-generating-sql-scripts-offline-mode)
5. [The Importance of Naming Constraints](#5-the-importance-of-naming-constraints)
6. [Running "Batch" Migrations for SQLite](#6-running-batch-migrations-for-sqlite)
7. [Working with Branches](#7-working-with-branches)
8. [Operation Reference](#8-operation-reference)
9. [Cookbook](#9-cookbook)
10. [API Details](#10-api-details)

---

## 1. Installation & Front Matter

### Installation

Install Alembic into a virtual environment:

```bash
cd /path/to/yourproject
python -m venv .venv
source /path/to/yourproject/.venv/bin/activate
pip install alembic
```

The install will add the `alembic` command to the virtual environment. Initialize with:

```bash
alembic init alembic
```

If your project is installable (has a `pyproject.toml` or `setup.py`):

```bash
pip install -e .
```

### Dependencies

Alembic's install process will ensure that SQLAlchemy is installed, in addition to other dependencies. Alembic will work with SQLAlchemy as of version **1.4.0** (support for older versions was dropped in 1.15.0). Alembic supports Python versions **3.9 and above** (changed in 1.15).

### Versioning Scheme

Alembic uses a three-number versioning scheme but **does not use SemVer**. The middle digit is a "Significant Minor Release" which may include removal of previously deprecated APIs. When pinning, pin to the "major" and "minor" digits to avoid API changes.

---

## 2. Tutorial

### The Migration Environment

Usage of Alembic starts with creation of the *Migration Environment* — a directory of scripts specific to a particular application, created just once and maintained along with source code.

Structure after generating some migration scripts:

```
yourproject/
    alembic.ini
    pyproject.toml
    alembic/
        env.py
        README
        script.py.mako
        versions/
            3512b954651e_add_account.py
            2b1ae634e5cd_add_order_id.py
            3adcc9a56557_rename_username_field.py
```

Key files:

- **`alembic.ini`** — Main configuration file, generated by all templates.
- **`env.py`** — Python script run whenever the alembic migration tool is invoked. Contains instructions to configure and generate a SQLAlchemy engine, procure a connection with a transaction, and invoke the migration engine. Fully customizable.
- **`script.py.mako`** — Mako template file used to generate new migration scripts.
- **`versions/`** — Holds individual version scripts using partial GUID approach. Ordering is relative to directives within the scripts (not ascending integers).

### Creating an Environment

```bash
cd /path/to/yourproject
source /path/to/yourproject/.venv/bin/activate
alembic init alembic
```

Available templates:

```bash
$ alembic list_templates
Available templates:

generic - Generic single-database configuration.
pyproject - pep-621 compliant configuration that includes pyproject.toml
async - Generic single-database configuration with an async dbapi.
multidb - Rudimentary multi-database configuration.
```

New in 1.16.0: `pyproject` template. See [Using pyproject.toml](#using-pyprojecttoml-for-configuration).

### Editing the .ini File

Key configuration options in `alembic.ini`:

```ini
[alembic]
# path to migration scripts (only required key)
script_location = %(here)s/alembic

# template for migration file names (default: %%(rev)s_%%(slug)s)
# Uncomment for date-prepended files:
# file_template = %%(year)d_%%(month).2d_%%(day).2d_%%(hour).2d%%(minute).2d-%%(rev)s_%%(slug)s

# sys.path prepend
prepend_sys_path = .

# database URL (consumed by env.py)
sqlalchemy.url = driver://user:pass@localhost/dbname

# Use os.pathsep for path separators (default for new projects)
path_separator = os
```

**File template tokens:** `%%(rev)s`, `%%(slug)s`, `%%(epoch)s`, `%%(year)d`, `%%(month).2d`, `%%(day).2d`, `%%(hour).2d`, `%%(minute).2d`, `%%(second).2d`. The `file_template` may also include directory separators (requires `recursive_version_locations = true`, added in 1.18.0).

Other options: `timezone`, `truncate_slug_length` (default 40), `revision_environment`, `sourceless`, `version_locations`, `recursive_version_locations` (new in 1.10), `output_encoding`.

#### Escaping Characters in ini files

Percent signs not part of interpolation tokens like `%(here)s` must be doubled:

```ini
# This:
file_template = %%(year)d_%%(month).2d_%%(rev)s_%%(slug)s
# Produces: %(year)d_%(month).2d_%(rev)s_%(slug)s
```

For SQLAlchemy URLs with special characters in passwords, use `urllib.parse.quote_plus`, then double percent signs for ConfigParser:

```python
import urllib.parse
password = urllib.parse.quote_plus("P@ssw%rd")  # P%40ssw%25rd
# In alembic.ini: sqlalchemy.url = postgresql+psycopg2://scott:P%%40ssw%%25rd@localhost:5432/testdb
```

### Using pyproject.toml for configuration

*New in 1.16.0.* Source-code organization options can be placed in `pyproject.toml` under `[tool.alembic]`. Lists are supported directly (e.g., `prepend_sys_path`, `version_locations`):

```bash
alembic init --template pyproject alembic
```

```toml
[tool.alembic]
script_location = "%(here)s/alembic"
prepend_sys_path = ["."]
# version_locations = ["%(here)s/alembic/versions", "%(here)s/foo/bar"]
```

The `alembic.ini` is still used for database URLs and logging. If `env.py` obtains these from elsewhere, `alembic.ini` can be omitted entirely.

### Create a Migration Script

```bash
$ alembic revision -m "create account table"
Generating /path/to/yourproject/alembic/versions/1975ea83b712_create_account_table.py...done
```

Generated file structure:

```python
"""create account table

Revision ID: 1975ea83b712
Revises:
Create Date: 2011-11-08 11:40:27.089406
"""

revision = '1975ea83b712'
down_revision = None
branch_labels = None

from alembic import op
import sqlalchemy as sa

def upgrade():
    pass

def downgrade():
    pass
```

Populate `upgrade()` and `downgrade()`:

```python
def upgrade():
    op.create_table(
        'account',
        sa.Column('id', sa.Integer, primary_key=True),
        sa.Column('name', sa.String(50), nullable=False),
        sa.Column('description', sa.Unicode(200)),
    )

def downgrade():
    op.drop_table('account')
```

The `down_revision` links files in order. `None` represents the first file.

### Running Migrations

```bash
# Upgrade to latest
$ alembic upgrade head

# Upgrade to specific revision
$ alembic upgrade ae1027a6acf

# Partial revision identifiers work
$ alembic upgrade ae1

# Relative migrations
$ alembic upgrade +2
$ alembic downgrade -1
$ alembic upgrade ae10+2

# Downgrade to nothing
$ alembic downgrade base

# View current revision
$ alembic current

# View history
$ alembic history --verbose

# View history ranges
$ alembic history -r1975ea:ae1027
$ alembic history -r-3:current
$ alembic history -r1975ea:
```

---

## 3. Auto Generating Migrations

Alembic can compare the current database schema against table metadata in your application and generate "candidate" migrations.

### Setup

Modify `env.py` to provide `target_metadata`:

```python
# Change from:
target_metadata = None

# To:
from myapp.mymodel import Base
target_metadata = Base.metadata
```

Then run:

```bash
$ alembic revision --autogenerate -m "Added account table"
INFO [alembic.context] Detected added table 'account'
Generating /path/to/foo/alembic/versions/27c6a30d7c24.py...done
```

**Always manually review and correct candidate migrations.**

### What Autogenerate Detects

**Will detect:**
- Table additions, removals
- Column additions, removals
- Change of nullable status on columns
- Basic changes in indexes and explicitly-named unique constraints
- Basic changes in foreign key constraints

**Optionally detects:**
- Change of column type (enabled by default since 1.12.0; set `compare_type=False` to disable)
- Change of server default (set `compare_server_default=True` to enable)

**Cannot detect:**
- Changes of table name (shows as add/drop pair)
- Changes of column name (shows as column add/drop pair)
- Anonymously named constraints
- Special SQLAlchemy types like `Enum` on backends without native ENUM support

**Cannot currently, but will eventually detect:**
- Some free-standing constraint additions/removals (PRIMARY KEY, EXCLUDE, CHECK)
- Sequence additions, removals

**Notable 3rd-party extensions:**
- [alembic-utils](https://github.com/olirice/alembic_utils) — autogenerate support for PostgreSQL functions, views, triggers
- [alembic-postgresql-enum](https://pypi.org/project/alembic-postgresql-enum) — autogenerate support for PostgreSQL Enums

### Multiple MetaData Collections

```python
from myapp.mymodel1 import Model1Base
from myapp.mymodel2 import Model2Base
target_metadata = [Model1Base.metadata, Model2Base.metadata]
```

Each `MetaData` must contain unique table keys (schema + name).

### Controlling What Gets Autogenerated

#### Omitting Schemas

```python
def include_name(name, type_, parent_names):
    if type_ == "schema":
        return name in [None, "schema_one", "schema_two"]  # None = default schema
    else:
        return True

context.configure(
    include_schemas=True,
    include_name=include_name
)
```

#### Omitting Tables

```python
target_metadata = MyModel.metadata

def include_name(name, type_, parent_names):
    if type_ == "schema":
        return name in [None, "schema_one", "schema_two"]
    elif type_ == "table":
        return parent_names["schema_qualified_table_name"] in target_metadata.tables
    else:
        return True

context.configure(
    target_metadata=target_metadata,
    include_name=include_name,
    include_schemas=True
)
```

#### Object-Level Filtering

```python
def include_object(object, name, type_, reflected, compare_to):
    if (type_ == "column" and not reflected and
        object.info.get("skip_autogenerate", False)):
        return False
    else:
        return True

context.configure(include_object=include_object)
```

### Controlling Module Prefix

```python
context.configure(
    connection=connection,
    target_metadata=target_metadata,
    sqlalchemy_module_prefix="sqla.",          # default: "sa."
    user_module_prefix="myapp.migration_types.",  # for custom types
)
```

### Comparing Types

Default comparison is enabled (since 1.12.0). Custom comparison:

```python
def my_compare_type(context, inspected_column, metadata_column, inspected_type, metadata_type):
    # Return False = same, True = different, None = use default
    return None

context.configure(compare_type=my_compare_type)
```

### Post Write Hooks (Code Formatters)

Configure in `alembic.ini`:

```ini
[post_write_hooks]
hooks = black, ruff

black.type = console_scripts
black.entrypoint = black
black.options = -l 79 REVISION_SCRIPT_FILENAME

ruff.type = exec
ruff.executable = ruff
ruff.options = check --fix REVISION_SCRIPT_FILENAME
```

Or in `pyproject.toml`:

```toml
[[tool.alembic.post_write_hooks]]
name = "black"
type = "console_scripts"
entrypoint = "black"
options = "-l 79 REVISION_SCRIPT_FILENAME"
```

Hook types: `console_scripts` (Python entrypoint), `exec` (arbitrary binary, new in 1.12), `module` (Python module, new in 1.16.3). Custom hooks can be registered with `@write_hooks.register("name")`.

### Alembic Check

*New in 1.9.0.* Test if new autogenerate operations would be detected without generating files:

```bash
$ alembic check
FAILED: New upgrade operations detected: [...]

$ alembic check
No new upgrade operations detected.
```

---

## 4. Generating SQL Scripts (Offline Mode)

Generate migrations as SQL scripts instead of running against the database:

```bash
$ alembic upgrade ae1027a6acf --sql > migration.sql
```

### Specifying Start Version

In offline mode, provide a range:

```bash
$ alembic upgrade 1975ea83b712:ae1027a6acf --sql > migration.sql
```

Or configure `env.py` to read the current version from a local file.

### Customizing the Environment

The `env.py` is split into `run_migrations_online()` and `run_migrations_offline()`. The `is_offline_mode()` method determines which runs. The `output_buffer` parameter on `configure()` allows directing output to named files (useful for multi-database setups).

---

## 5. The Importance of Naming Constraints

Database backends generate different constraint names (PostgreSQL: `user_order_user_account_id_fkey`, Oracle: `SYS_C0029334`). Use **automated naming conventions** for portability:

```python
convention = {
    "ix": "ix_%(column_0_label)s",
    "uq": "uq_%(table_name)s_%(column_0_name)s",
    "ck": "ck_%(table_name)s_%(constraint_name)s",
    "fk": "fk_%(table_name)s_%(column_0_name)s_%(referred_table_name)s",
    "pk": "pk_%(table_name)s"
}

metadata = MetaData(naming_convention=convention)
```

With declarative:

```python
from sqlalchemy.orm import DeclarativeBase

class Base(DeclarativeBase):
    metadata = MetaData(naming_convention={
        "ix": "ix_%(column_0_label)s",
        "uq": "uq_%(table_name)s_%(column_0_name)s",
        "ck": "ck_%(table_name)s_`%(constraint_name)s`",
        "fk": "fk_%(table_name)s_%(column_0_name)s_%(referred_table_name)s",
        "pk": "pk_%(table_name)s"
    })
```

This integrates with `Operations` via `target_metadata` (since Alembic 0.6.4). Use `op.f("name")` to bypass naming conventions:

```python
op.drop_constraint(op.f("some_check_const"), "t1", type_="check")
# Emits: ALTER TABLE t1 DROP CONSTRAINT some_check_const  (no convention applied)
```

---

## 6. Running "Batch" Migrations for SQLite

SQLite has almost no ALTER support. Alembic provides **batch operations** that use "move and copy" — reflect the table, create a new version with changes, INSERT from SELECT, drop the old, rename the new:

```python
with op.batch_alter_table("some_table") as batch_op:
    batch_op.add_column(Column('foo', Integer))
    batch_op.drop_column('bar')
```

On SQLite this generates:

```sql
CREATE TABLE _alembic_batch_temp (id INTEGER NOT NULL, foo INTEGER, PRIMARY KEY (id));
INSERT INTO _alembic_batch_temp (id) SELECT some_table.id FROM some_table;
DROP TABLE some_table;
ALTER TABLE _alembic_batch_temp RENAME TO some_table;
```

On other backends, normal ALTER statements are emitted (unless `recreate='always'` is passed).

### Key Considerations

**Controlling table reflection:** Use `reflect_args` and `reflect_kwargs` on `batch_alter_table()`.

**Constraints:**
- Unnamed foreign keys require `naming_convention` argument on `batch_alter_table()`.
- Named CHECK constraints are automatically included (since 1.7). Unnamed CHECK constraints must be stated via `table_args`.
- `Boolean` and `Enum` types must be named for their CHECK constraints to be regenerated.

**Foreign keys:** Batch operations don't work with enforced referential integrity. On SQLite, disable `PRAGMA FOREIGN KEYS` during migration. Self-referencing FKs are handled specially.

**Offline mode:** Requires `copy_from` parameter with a pre-fabricated `Table` object.

**Autogenerate:** Use `render_as_batch=True` in `context.configure()`:

```python
context.configure(
    connection=connection,
    target_metadata=target_metadata,
    render_as_batch=True
)
```

Safe to use in all cases — only takes effect for SQLite by default.

---

## 7. Working with Branches

A **branch** is when two or more versions refer to the same parent migration.

### Detecting Branches

```bash
$ alembic branches --verbose
$ alembic heads --verbose
$ alembic history
```

### Merging Branches

Create a merge file joining multiple heads into a diamond structure:

```bash
$ alembic merge -m "merge ae1 and 27c" ae1027 27c6a
```

The merge file has `down_revision` as a tuple:

```python
revision = '53fffde5ad5'
down_revision = ('ae1027a6acf', '27c6a30d7c24')
```

The merge process uses **topological sorting** (directed acyclic graph). The `alembic_version` table may store multiple rows when at multiple heads.

### Branch Labels

Add labels to migration files:

```python
branch_labels = ('shoppingcart',)
```

Use labels in commands:

```bash
$ alembic upgrade shoppingcart@head
$ alembic revision -m "add column" --head shoppingcart@head
$ alembic history -r shoppingcart:
$ alembic history -r :shoppingcart@head
$ alembic upgrade shoppingcart@heads   # all heads in branch
$ alembic upgrade shoppingcart@+2      # relative
```

### Multiple Bases (Independent Trees)

Set up multiple version directories in `alembic.ini`:

```ini
path_separator = os
version_locations = %(here)s/model/networking:%(here)s/alembic/versions
```

Create a new labeled base:

```bash
$ alembic revision -m "create networking branch" \
    --head=base --branch-label=networking \
    --version-path=model/networking
```

Add revisions to the branch:

```bash
$ alembic revision -m "add ip number table" --head=networking@head
```

Upgrade individually or all at once:

```bash
$ alembic upgrade networking@head
$ alembic upgrade heads
```

### Branch Dependencies

Use `depends_on` for cross-branch dependencies without merging:

```bash
$ alembic revision -m "add ip account table" \
    --head=networking@head --depends-on=55af2cb1c267
```

```python
revision = '2a95102259be'
down_revision = '29f859a13ea'
depends_on = '55af2cb1c267'
```

The dependency ensures that revision is applied before the dependent one during upgrades, but is not affected during downgrades.

---

## 8. Operation Reference

All directives exist as methods on the `Operations` class, accessed via `alembic.op` in migration scripts. The system is extensible via [Operation Plugins](#operation-plugins).

Key design: operations internally generate SQLAlchemy metadata (`Table`, `Constraint` objects) so migration instructions can use string names and flags. Exceptions: `add_column` and `create_table` require full `Column` objects.

The operations include (see Alembic API docs for full signatures):

- **Table ops:** `create_table()`, `drop_table()`, `rename_table()`
- **Column ops:** `add_column()`, `drop_column()`, `alter_column()`
- **Index ops:** `create_index()`, `drop_index()`
- **Constraint ops:** `create_unique_constraint()`, `create_check_constraint()`, `create_foreign_key()`, `create_primary_key()`, `drop_constraint()`
- **Batch ops:** `batch_alter_table()` context manager → `BatchOperations`
- **Data ops:** `bulk_insert()`, `execute()`
- **Utility:** `f()` (bypass naming conventions), `get_context()`, `get_bind()`, `invoke()`

---

## 9. Cookbook

### Building an Up to Date Database from Scratch

Use `create_all()` for new databases, then stamp with the latest revision:

```python
my_metadata.create_all(engine)

from alembic.config import Config
from alembic import command
alembic_cfg = Config("/path/to/yourapp/alembic.ini")
command.stamp(alembic_cfg, "head")
```

To prune old migrations: delete old files, set `down_revision = None` in the earliest remaining file.

### Conditional Migration Elements

Use `-x` flags to control behavior:

```python
from alembic import context

def upgrade():
    schema_upgrades()
    if context.get_x_argument(as_dictionary=True).get('data', None):
        data_upgrades()
```

```bash
alembic -x data=true upgrade head
```

### Sharing a Connection Across Commands

```python
from alembic import command, config

cfg = config.Config("/path/to/yourapp/alembic.ini")
with engine.begin() as connection:
    cfg.attributes['connection'] = connection
    command.upgrade(cfg, "head")
```

In `env.py`:

```python
def run_migrations_online():
    connectable = config.attributes.get('connection', None)
    if connectable is None:
        connectable = engine_from_config(...)
        with connectable.connect() as connection:
            context.configure(connection=connection, target_metadata=target_metadata)
            with context.begin_transaction():
                context.run_migrations()
    else:
        context.configure(connection=connectable, target_metadata=target_metadata)
        with context.begin_transaction():
            context.run_migrations()
```

### Replaceable Objects (Views, Stored Procedures, Triggers)

See also: [alembic-utils](https://github.com/olirice/alembic_utils) for production-ready PostgreSQL support.

Define a simple value object:

```python
class ReplaceableObject:
    def __init__(self, name, sqltext):
        self.name = name
        self.sqltext = sqltext
```

Create custom operations using the Operations extension API:

```python
from alembic.operations import Operations, MigrateOperation

class ReversibleOp(MigrateOperation):
    def __init__(self, target):
        self.target = target

    @classmethod
    def invoke_for_target(cls, operations, target):
        op = cls(target)
        return operations.invoke(op)

    def reverse(self):
        raise NotImplementedError()

    @classmethod
    def _get_object_from_version(cls, operations, ident):
        version, objname = ident.split(".")
        module = operations.get_context().script.get_revision(version).module
        return getattr(module, objname)

    @classmethod
    def replace(cls, operations, target, replaces=None, replace_with=None):
        if replaces:
            old_obj = cls._get_object_from_version(operations, replaces)
            drop_old = cls(old_obj).reverse()
            create_new = cls(target)
        elif replace_with:
            old_obj = cls._get_object_from_version(operations, replace_with)
            drop_old = cls(target).reverse()
            create_new = cls(old_obj)
        else:
            raise TypeError("replaces or replace_with is required")
        operations.invoke(drop_old)
        operations.invoke(create_new)

@Operations.register_operation("create_view", "invoke_for_target")
@Operations.register_operation("replace_view", "replace")
class CreateViewOp(ReversibleOp):
    def reverse(self):
        return DropViewOp(self.target)

@Operations.register_operation("drop_view", "invoke_for_target")
class DropViewOp(ReversibleOp):
    def reverse(self):
        return CreateViewOp(self.target)
```

Register implementations:

```python
@Operations.implementation_for(CreateViewOp)
def create_view(operations, operation):
    operations.execute("CREATE VIEW %s AS %s" % (operation.target.name, operation.target.sqltext))

@Operations.implementation_for(DropViewOp)
def drop_view(operations, operation):
    operations.execute("DROP VIEW %s" % operation.target.name)
```

Use in migrations with `replaces`/`replace_with` for versioned replacements:

```python
def upgrade():
    op.replace_view(customer_view, replaces="28af9800143f.customer_view")

def downgrade():
    op.replace_view(customer_view, replace_with="28af9800143f.customer_view")
```

### Schema-Level Multi Tenancy (PostgreSQL / MySQL)

Use `-x` flag to pass tenant schema. In `env.py`:

```python
from sqlalchemy import text

def run_migrations_online():
    connectable = engine_from_config(...)
    current_tenant = context.get_x_argument(as_dictionary=True).get("tenant")

    with connectable.connect() as connection:
        if connection.dialect.name == "postgresql":
            connection.execute(text('set search_path to "%s"' % current_tenant))
            connection.commit()
        elif connection.dialect.name in ("mysql", "mariadb"):
            connection.execute(text('USE %s' % current_tenant))

        connection.dialect.default_schema_name = current_tenant

        context.configure(connection=connection, target_metadata=target_metadata)
        with context.begin_transaction():
            context.run_migrations()
```

```bash
alembic -x tenant=some_schema revision -m "rev1" --autogenerate
```

### Don't Generate Empty Migrations

```python
def process_revision_directives(context, revision, directives):
    if getattr(config.cmd_opts, 'autogenerate', False):
        script = directives[0]
        if script.upgrade_ops.is_empty():
            directives[:] = []

context.configure(
    connection=connection,
    target_metadata=target_metadata,
    process_revision_directives=process_revision_directives
)
```

### Using Asyncio with Alembic

Bootstrap with the async template:

```bash
alembic init -t async <script_directory_here>
```

Or update existing `env.py`:

```python
import asyncio
from sqlalchemy.ext.asyncio import async_engine_from_config

def do_run_migrations(connection):
    context.configure(connection=connection, target_metadata=target_metadata)
    with context.begin_transaction():
        context.run_migrations()

async def run_async_migrations():
    connectable = async_engine_from_config(
        config.get_section(config.config_ini_section),
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )
    async with connectable.connect() as connection:
        await connection.run_sync(do_run_migrations)
    await connectable.dispose()

def run_migrations_online():
    asyncio.run(run_async_migrations())
```

#### Programmatic Async with Connection Sharing

```python
import asyncio
from sqlalchemy.ext.asyncio import create_async_engine
from alembic import command, config

def run_upgrade(connection, cfg):
    cfg.attributes["connection"] = connection
    command.upgrade(cfg, "head")

async def run_async_upgrade():
    async_engine = create_async_engine("sqlite+aiosqlite://", echo=True)
    async with async_engine.begin() as conn:
        await conn.run_sync(run_upgrade, config.Config("alembic.ini"))

asyncio.run(run_async_upgrade())
```

### Don't Emit DROP TABLE Directives

```python
def include_object(object, name, type_, reflected, compare_to):
    if type_ == "table" and reflected and compare_to is None:
        return False
    else:
        return True

context.configure(include_object=include_object)
```

### Check Database Is at Head

*New in 1.17.1:* Built into `alembic current --check-heads`.

Programmatic:

```python
from alembic import config, script
from alembic.runtime import migration

def check_current_head(alembic_cfg, connectable):
    directory = script.ScriptDirectory.from_config(alembic_cfg)
    with connectable.begin() as connection:
        context = migration.MigrationContext.configure(connection)
        return set(context.get_current_heads()) == set(directory.get_heads())
```

### Run Multiple Environments from One .ini File

```ini
[DEFAULT]
sqlalchemy.url = postgresql://scott:tiger@hostname/mydatabase

[schema1]
script_location = myproject/revisions/schema1

[schema2]
script_location = myproject/revisions/schema2

[schema3]
script_location = myproject/revisions/db2
sqlalchemy.url = postgresql://scott:tiger@hostname/myotherdatabase
```

```bash
alembic --name schema2 revision -m "new rev for schema 2" --autogenerate
```

### Add IF [NOT] EXISTS to Operations

Using the rewriter:

```python
from alembic.operations import ops
from alembic.autogenerate import rewriter

writer = rewriter.Rewriter()

@writer.rewrites(ops.CreateTableOp)
@writer.rewrites(ops.CreateIndexOp)
def add_if_not_exists(context, revision, op):
    op.if_not_exists = True
    return op

@writer.rewrites(ops.DropTableOp)
@writer.rewrites(ops.DropIndexOp)
def add_if_exists(context, revision, op):
    op.if_exists = True
    return op
```

### Custom CLI Commands

*New in 1.15.3:*

```python
from alembic.config import CommandLine, Config

def frobnicate(config: Config, revision: str) -> None:
    """Frobnicates according to the frobnication specification."""
    config.print_stdout(f"Revision {revision} successfully frobnicated.")

def main():
    cli = CommandLine()
    cli.register_command(frobnicate)
    cli.main()
```

### Data Migrations

Alembic is designed for **schema** migrations. For data migrations:

- **Small data:** Use `op.bulk_insert()` within migrations.
- **Separate migration script:** Run schema migration → data script → final schema migration.
- **Online migration:** Application maintains dual-write with background data transfer (complex, requires custom application logic).

---

## 10. API Details

### Overview

The internal architecture flows as follows:

1. **`Config`** → parsed from `alembic.ini` / `pyproject.toml`
2. **`ScriptDirectory`** → represents the collection of version files
3. **`EnvironmentContext`** → configurational facade passed to `env.py`
4. **`MigrationContext`** → actual migration engine, gateway to the database
5. **`DefaultImpl`** (per-backend subclasses) → database communication, SQL generation
6. **`Operations`** → end-user interface to database operations
7. **Autogenerate** → schema comparison and revision script generation

### Runtime Objects

**`EnvironmentContext`** — provides most of the API used within `env.py`. Available as the proxy module `alembic.context`. Key method: `configure()`.

**`MigrationContext`** — handles actual work against a database backend. Not normally exposed to end users.

### Configuration

The `Config` object represents configuration passed to the Alembic environment. Needed for:
- Creating `ScriptDirectory`
- Creating `EnvironmentContext`
- Running commands programmatically

Not needed for:
- Instantiating `MigrationContext` directly (only needs a connection or dialect name)
- Instantiating `Operations` (only needs a `MigrationContext`)

### Commands (Programmatic Usage)

All commands accept a `Config` as the first argument:

```python
from alembic.config import Config
from alembic import command

alembic_cfg = Config("/path/to/yourapp/alembic.ini")
command.upgrade(alembic_cfg, "head")
```

Share a connection across multiple commands:

```python
with engine.begin() as connection:
    alembic_cfg.attributes['connection'] = connection
    command.upgrade(alembic_cfg, "head")
```

### Operation Plugins

Extend the `op.*` namespace with custom operations:

```python
from alembic.operations import Operations, MigrateOperation

@Operations.register_operation("create_sequence")
class CreateSequenceOp(MigrateOperation):
    def __init__(self, sequence_name, schema=None):
        self.sequence_name = sequence_name
        self.schema = schema

    @classmethod
    def create_sequence(cls, operations, sequence_name, **kw):
        """Issue a "CREATE SEQUENCE" instruction."""
        op = CreateSequenceOp(sequence_name, **kw)
        return operations.invoke(op)

    def reverse(self):
        return DropSequenceOp(self.sequence_name, schema=self.schema)

@Operations.implementation_for(CreateSequenceOp)
def create_sequence(operations, operation):
    name = "%s.%s" % (operation.schema, operation.sequence_name) if operation.schema else operation.sequence_name
    operations.execute("CREATE SEQUENCE %s" % name)
```

Usage in migration scripts: `op.create_sequence("my_sequence")`

#### Extending Built-in Operations

*New in 1.17.2.* Replace existing implementations:

```python
from alembic.operations import Operations
from alembic.operations.ops import CreateTableOp
from alembic.operations.toimpl import create_table as _create_table

@Operations.implementation_for(CreateTableOp, replace=True)
def create_table_with_logging(operations, operation):
    _create_table(operations, operation)
    # ... additional logic
```

### Plugins

*New in 1.18.0.* Third-party extensions can integrate via Python entry points:

```bash
pip install mycompany-alembic-plugin
```

Manual registration in `env.py`:

```python
from alembic.runtime.plugins import Plugin
import myproject.alembic_plugin

Plugin.setup_plugin_from_module(myproject.alembic_plugin, "myproject.custom_operations")
```

Enable autogenerate plugins:

```python
context.configure(
    connection=connection,
    target_metadata=target_metadata,
    autogenerate_plugins=["alembic.autogenerate.*", "mycompany.*"]
)
```

### DDL Internals

Per-backend implementations for DDL generation. Subclasses of `DefaultImpl` exist for MySQL, MS-SQL, PostgreSQL, and SQLite. For programmatic usage, prefer the higher-level `Operations` API.

### Script Directory

`ScriptDirectory` provides programmatic access to version files. `RevisionMap` serves as the basis for revision management. `write_hooks` module handles post-generation processing.

---

*End of Alembic Documentation Master Reference*
